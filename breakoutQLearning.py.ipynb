{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The idea to create this model was sparked by a tweet: https://twitter.com/fchollet/status/711594805692792832\n",
    "\n",
    "I studied the following resources to be able to finish the model:\n",
    "0. http://artint.info/html/ArtInt_265.html\n",
    "1. https://edersantana.github.io/articles/keras_rl/\n",
    "2. http://www.nervanasys.com/demystifying-deep-reinforcement-learning/\n",
    "3. http://keras.io/\n",
    "\n",
    "Here's a gif of the model playing a few games of catching fruit:\n",
    "<img src=\"files/fruit.gif\" />\n",
    "\n",
    "Btw, I really, *really* liked Eder Santana's idea to apply big idea's to toy examples. I hope to do this more often to feed my fingerspitzengef√ºhl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from random import sample as rsample\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.layers import Input\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras import backend as K\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import color\n",
    "from scipy.misc import imresize\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-04-11 18:11:34,966] Making new env: Breakout-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(210, 160, 3)\n",
      "(210, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Breakout-v0')\n",
    "print env.observation_space\n",
    "\n",
    "img = env.reset()\n",
    "print img.shape\n",
    "\n",
    "def grayAndResize(img):\n",
    "    gray = color.rgb2grey(img)\n",
    "    newImg = imresize(gray, (84, 84))\n",
    "    return newImg\n",
    "\n",
    "def stackIt(images):\n",
    "    stage = np.zeros(shape = (1, 84, 84, 4))\n",
    "    for k, img in enumerate(images):\n",
    "        #print \"Image shape\", type(img)\n",
    "        stage[0, :, :, k] = grayAndResize(img)\n",
    "    return stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAM8AAAEACAYAAAAUSCKKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCo9IkMIjEqTwiAQpPCJBCo9I0P8DlklTQiPY1AMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6b944eaf90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD/CAYAAADRymv0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nD/1/Nv14W4lKX9cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6b3490e610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "(84, 84) (1, 84, 84, 4)\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "images = stackIt([img, img, img, img])\n",
    "\n",
    "images = images\n",
    "\n",
    "plt.imshow(images[0, :, :, 1])\n",
    "plt.show()\n",
    "print env.action_space.n\n",
    "print images[0, :, :, 1].shape, images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "           \n",
    "def experience_replay(batch_size):\n",
    "    \"\"\"\n",
    "    Coroutine of experience replay.\n",
    "    \n",
    "    Provide a new experience by calling send, which in turn yields \n",
    "    a random batch of previous replay experiences.\n",
    "    \"\"\"\n",
    "    memory = []\n",
    "    while True:\n",
    "        experience = yield rsample(memory, batch_size) if batch_size <= len(memory) else None\n",
    "        memory.append(experience)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_model(STATE_LENGTH, FRAME_WIDTH, FRAME_HEIGHT, output_size ,dir = None):\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, (8, 8), subsample=(4, 4), border_mode='same', activation='relu', input_shape = (84, 84, 4)))\n",
    "    model.add(Convolution2D(32, 4, 4, subsample=(2, 2), border_mode='same', activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(6))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 loss: 0 Reward: 0 Total Q: 0 Epsilon 0.76\n",
      "Epoch  2 loss: 0.0 Reward: 1.0 Total Q: 0 Epsilon 0.722\n",
      "Epoch  3 loss: 0.0 Reward: 1.0 Total Q: 0 Epsilon 0.6859\n",
      "Epoch  4 loss: 0.0 Reward: 1.0 Total Q: 0 Epsilon 0.651605\n",
      "Epoch  5 loss: 0.0 Reward: 0.0 Total Q: 0 Epsilon 0.61902475\n",
      "Epoch  6 loss: 110945.193522 Reward: 15.0 Total Q: -64844.2640514 Epsilon 0.5880735125\n",
      "Epoch  7 loss: 93.7624510527 Reward: 27.0 Total Q: 24316.5298462 Epsilon 0.558669836875\n",
      "Epoch  8 loss: 93.2302484661 Reward: 36.0 Total Q: 22355.3087769 Epsilon 0.530736345031\n",
      "Epoch  9 loss: 55.2916820645 Reward: 54.0 Total Q: 53490.2181396 Epsilon 0.50419952778\n",
      "Epoch  10 loss: 12.3516474366 Reward: 23.0 Total Q: 25612.9856567 Epsilon 0.478989551391\n",
      "Epoch  11 loss: 10.1721744686 Reward: 31.0 Total Q: 36799.166626 Epsilon 0.455040073821\n",
      "Epoch  12 loss: 203.027121812 Reward: 15.0 Total Q: 36566.367691 Epsilon 0.43228807013\n",
      "Epoch  13 loss: 4.57542561367 Reward: 10.0 Total Q: 39777.2330322 Epsilon 0.410673666624\n",
      "Epoch  14 loss: 8.72017361224 Reward: 24.0 Total Q: 47452.394165 Epsilon 0.390139983292\n",
      "Epoch  15 loss: 7.26801967621 Reward: 21.0 Total Q: 42942.0488586 Epsilon 0.370632984128\n",
      "Epoch  16 loss: 106.543243878 Reward: 24.0 Total Q: 49033.7497101 Epsilon 0.352101334921\n",
      "Epoch  17 loss: 10.3169271424 Reward: 25.0 Total Q: 48788.2647095 Epsilon 0.334496268175\n",
      "Epoch  18 loss: 18.5603693798 Reward: 47.0 Total Q: 76366.7519531 Epsilon 0.317771454767\n",
      "Epoch  19 loss: 12.3744237423 Reward: 29.0 Total Q: 61095.4540405 Epsilon 0.301882882028\n",
      "Epoch  20 loss: 6.26177813858 Reward: 13.0 Total Q: 31499.7359009 Epsilon 0.286788737927\n",
      "Epoch  21 loss: 17.8369942829 Reward: 29.0 Total Q: 64535.8788452 Epsilon 0.27244930103\n",
      "Epoch  22 loss: 6.28061746806 Reward: 16.0 Total Q: 40153.3571777 Epsilon 0.258826835979\n",
      "Epoch  23 loss: 7.77065806091 Reward: 27.0 Total Q: 53744.0106812 Epsilon 0.24588549418\n",
      "Epoch  24 loss: 7.62182482332 Reward: 30.0 Total Q: 60611.0098877 Epsilon 0.233591219471\n",
      "Epoch  25 loss: 7.6749221161 Reward: 39.0 Total Q: 63914.644165 Epsilon 0.221911658497\n",
      "Epoch  26 loss: 5.52751195431 Reward: 33.0 Total Q: 54854.9691162 Epsilon 0.210816075573\n",
      "Epoch  27 loss: 7.65708358586 Reward: 27.0 Total Q: 61149.9368896 Epsilon 0.200275271794\n",
      "Epoch  28 loss: 13.3057204634 Reward: 34.0 Total Q: 48563.2086792 Epsilon 0.190261508204\n",
      "Epoch  29 loss: 11.3669911176 Reward: 38.0 Total Q: 66967.0182495 Epsilon 0.180748432794\n",
      "Epoch  30 loss: 7.61210918427 Reward: 40.0 Total Q: 55380.4492493 Epsilon 0.171711011154\n",
      "Epoch  31 loss: 11.0943617076 Reward: 36.0 Total Q: 66421.369812 Epsilon 0.163125460597\n",
      "Epoch  32 loss: 9.59951046109 Reward: 34.0 Total Q: 62687.9432602 Epsilon 0.154969187567\n",
      "Epoch  33 loss: 11.3951737583 Reward: 24.0 Total Q: 48568.3032227 Epsilon 0.147220728188\n",
      "Epoch  34 loss: 10.9861709364 Reward: 47.0 Total Q: 50616.5507202 Epsilon 0.139859691779\n",
      "Epoch  35 loss: 10.2582214773 Reward: 33.0 Total Q: 52533.5700684 Epsilon 0.13286670719\n",
      "Epoch  36 loss: 6.72406961024 Reward: 15.0 Total Q: 26817.2318115 Epsilon 0.126223371831\n",
      "Epoch  37 loss: 17.3220439106 Reward: 46.0 Total Q: 66158.9177246 Epsilon 0.119912203239\n",
      "Epoch  38 loss: 6.60851222277 Reward: 30.0 Total Q: 28782.8297729 Epsilon 0.113916593077\n",
      "Epoch  39 loss: 10.6717873216 Reward: 19.0 Total Q: 35134.1785431 Epsilon 0.108220763423\n",
      "Epoch  40 loss: 6.89255000651 Reward: 28.0 Total Q: 33602.06604 Epsilon 0.102809725252\n",
      "Epoch  41 loss: 10.7119811773 Reward: 30.0 Total Q: 48336.6951904 Epsilon 0.0976692389895\n",
      "Epoch  42 loss: 17.1259410679 Reward: 59.0 Total Q: 75531.2580261 Epsilon 0.09278577704\n",
      "Epoch  43 loss: 16.5986769944 Reward: 37.0 Total Q: 69174.6595459 Epsilon 0.088146488188\n",
      "Epoch  44 loss: 6.64115873724 Reward: 17.0 Total Q: 28898.3147583 Epsilon 0.0837391637786\n",
      "Epoch  45 loss: 4.62532797456 Reward: 27.0 Total Q: 30502.019043 Epsilon 0.0795522055897\n",
      "Epoch  46 loss: 9.43113586307 Reward: 34.0 Total Q: 46184.338623 Epsilon 0.0755745953102\n",
      "Epoch  47 loss: 5.31532914937 Reward: 19.0 Total Q: 35013.5988159 Epsilon 0.0717958655447\n",
      "Epoch  48 loss: 16.6888253577 Reward: 36.0 Total Q: 45424.7794342 Epsilon 0.0682060722674\n",
      "Epoch  49 loss: 12.7266289741 Reward: 24.0 Total Q: 46982.1962128 Epsilon 0.0647957686541\n",
      "Epoch  50 loss: 9.87668197602 Reward: 40.0 Total Q: 42494.8433228 Epsilon 0.0615559802214\n",
      "Epoch  51 loss: 12.9060982093 Reward: 39.0 Total Q: 57766.928215 Epsilon 0.0584781812103\n",
      "Epoch  52 loss: 9.81303897873 Reward: 32.0 Total Q: 29744.2539368 Epsilon 0.0555542721498\n",
      "Epoch  53 loss: 9.10132728517 Reward: 25.0 Total Q: 36110.0667725 Epsilon 0.0527765585423\n",
      "Epoch  54 loss: 11.971032761 Reward: 36.0 Total Q: 66922.749054 Epsilon 0.0501377306152\n",
      "Epoch  55 loss: 6.12069334835 Reward: 17.0 Total Q: 29190.8957672 Epsilon 0.0476308440844\n",
      "Epoch  56 loss: 4.2655635979 Reward: 29.0 Total Q: 21953.5948334 Epsilon 0.0476308440844\n",
      "Epoch  57 loss: 10.9052536599 Reward: 23.0 Total Q: 45001.2513428 Epsilon 0.0476308440844\n",
      "Epoch  58 loss: 13.9148828611 Reward: 34.0 Total Q: 65596.944088 Epsilon 0.0476308440844\n",
      "Epoch  59 loss: 4.22116148099 Reward: 20.0 Total Q: 29147.475769 Epsilon 0.0476308440844\n",
      "Epoch  60 loss: 10.1652723867 Reward: 23.0 Total Q: 41102.7296448 Epsilon 0.0476308440844\n",
      "Epoch  61 loss: 5.46557131782 Reward: 25.0 Total Q: 29702.3384819 Epsilon 0.0476308440844\n",
      "Epoch  62 loss: 15.8479777053 Reward: 52.0 Total Q: 80563.8313599 Epsilon 0.0476308440844\n",
      "Epoch  63 loss: 6.11277333647 Reward: 18.0 Total Q: 47750.9123535 Epsilon 0.0476308440844\n",
      "Epoch  64 loss: 6.47202754952 Reward: 22.0 Total Q: 11335.6701927 Epsilon 0.0476308440844\n",
      "Epoch  65 loss: 8.90496067703 Reward: 25.0 Total Q: 36087.3087921 Epsilon 0.0476308440844\n",
      "Epoch  66 loss: 5.29616555199 Reward: 22.0 Total Q: 33361.0139513 Epsilon 0.0476308440844\n",
      "Epoch  67 loss: 8.97866725922 Reward: 17.0 Total Q: 34776.3360596 Epsilon 0.0476308440844\n",
      "Epoch  68 loss: 10.8799757175 Reward: 25.0 Total Q: 56780.8132877 Epsilon 0.0476308440844\n",
      "Epoch  69 loss: 3.43816863559 Reward: 17.0 Total Q: 9389.31144714 Epsilon 0.0476308440844\n",
      "Epoch  70 loss: 4.59366773814 Reward: 27.0 Total Q: 21009.8628693 Epsilon 0.0476308440844\n",
      "Epoch  71 loss: 7.23996932432 Reward: 37.0 Total Q: 32570.6582489 Epsilon 0.0476308440844\n",
      "Epoch  72 loss: 5.90485518053 Reward: 28.0 Total Q: 17804.087326 Epsilon 0.0476308440844\n",
      "Epoch  73 loss: 15.1175610721 Reward: 48.0 Total Q: 37929.6877441 Epsilon 0.0476308440844\n",
      "Epoch  74 loss: 9.97409814596 Reward: 27.0 Total Q: 41310.4071808 Epsilon 0.0476308440844\n",
      "Epoch  75 loss: 17.0099255852 Reward: 26.0 Total Q: 41933.2001038 Epsilon 0.0476308440844\n",
      "Epoch  76 loss: 13.9126769677 Reward: 25.0 Total Q: 55109.061142 Epsilon 0.0476308440844\n",
      "Epoch  77 loss: 7.36863839626 Reward: 20.0 Total Q: 22592.0097961 Epsilon 0.0476308440844\n",
      "Epoch  78 loss: 11.2874199646 Reward: 27.0 Total Q: 33971.4798927 Epsilon 0.0476308440844\n",
      "Epoch  79 loss: 7.1106929332 Reward: 19.0 Total Q: 38177.6426392 Epsilon 0.0476308440844\n",
      "Epoch  80 loss: 10.8303690106 Reward: 35.0 Total Q: 80043.036499 Epsilon 0.0476308440844\n",
      "Epoch  81 loss: 4.51319474354 Reward: 7.0 Total Q: 45657.9459229 Epsilon 0.0476308440844\n",
      "Epoch  82 loss: 10.5622660089 Reward: 33.0 Total Q: 95883.7467041 Epsilon 0.0476308440844\n",
      "Epoch  83 loss: 6.63454867899 Reward: 12.0 Total Q: 31351.8533554 Epsilon 0.0476308440844\n",
      "Epoch  84 loss: 4.54501396045 Reward: 29.0 Total Q: 42014.9551539 Epsilon 0.0476308440844\n",
      "Epoch  85 loss: 12.9052040428 Reward: 28.0 Total Q: 45692.8515625 Epsilon 0.0476308440844\n",
      "Epoch  86 loss: 9.35278876498 Reward: 21.0 Total Q: 37549.8644257 Epsilon 0.0476308440844\n",
      "Epoch  87 loss: 11.2781239487 Reward: 18.0 Total Q: 43374.225769 Epsilon 0.0476308440844\n",
      "Epoch  88 loss: 8.57666626573 Reward: 15.0 Total Q: 35184.0020752 Epsilon 0.0476308440844\n",
      "Epoch  89 loss: 9.22011914104 Reward: 27.0 Total Q: 42463.8766174 Epsilon 0.0476308440844\n",
      "Epoch  90 loss: 5.00182826445 Reward: 23.0 Total Q: 55228.6932983 Epsilon 0.0476308440844\n",
      "Epoch  91 loss: 10.4664943889 Reward: 20.0 Total Q: 56463.3065491 Epsilon 0.0476308440844\n",
      "Epoch  92 loss: 11.8930456713 Reward: 24.0 Total Q: 37251.3580017 Epsilon 0.0476308440844\n",
      "Epoch  93 loss: 12.9790100902 Reward: 41.0 Total Q: 63295.5317535 Epsilon 0.0476308440844\n",
      "Epoch  94 loss: 12.6599618606 Reward: 23.0 Total Q: 60247.1248474 Epsilon 0.0476308440844\n",
      "Epoch  95 loss: 3.68465689197 Reward: 20.0 Total Q: 17083.4515991 Epsilon 0.0476308440844\n",
      "Epoch  96 loss: 10.4739347771 Reward: 25.0 Total Q: 83803.8069458 Epsilon 0.0476308440844\n",
      "Epoch  97 loss: 10.8205640372 Reward: 23.0 Total Q: 90827.5860596 Epsilon 0.0476308440844\n",
      "Epoch  98 loss: 5.36291951919 Reward: 9.0 Total Q: 20499.5031815 Epsilon 0.0476308440844\n",
      "Epoch  99 loss: 6.76939665899 Reward: 15.0 Total Q: 25748.7968903 Epsilon 0.0476308440844\n",
      "Epoch  100 loss: 7.41252904199 Reward: 27.0 Total Q: 44658.0213013 Epsilon 0.0476308440844\n",
      "Epoch  101 loss: 7.87301620096 Reward: 19.0 Total Q: 52859.5317078 Epsilon 0.0476308440844\n",
      "Epoch  102 loss: 11.3175322302 Reward: 28.0 Total Q: 60510.5480347 Epsilon 0.0476308440844\n",
      "Epoch  103 loss: 4.68505635671 Reward: 24.0 Total Q: 68975.9467773 Epsilon 0.0476308440844\n",
      "Epoch  104 loss: 4.85543557629 Reward: 18.0 Total Q: 59760.453125 Epsilon 0.0476308440844\n",
      "Epoch  105 loss: 9.20428332128 Reward: 41.0 Total Q: 63325.2282257 Epsilon 0.0476308440844\n",
      "Epoch  106 loss: 12.6160388654 Reward: 39.0 Total Q: 52182.6469154 Epsilon 0.0476308440844\n",
      "Epoch  107 loss: 7.72209621593 Reward: 26.0 Total Q: 80545.52771 Epsilon 0.0476308440844\n",
      "Epoch  108 loss: 9.28213680536 Reward: 20.0 Total Q: 57582.7576904 Epsilon 0.0476308440844\n",
      "Epoch  109 loss: 5.75609945506 Reward: 22.0 Total Q: 57630.0210571 Epsilon 0.0476308440844\n",
      "Epoch  110 loss: 5.17258037627 Reward: 23.0 Total Q: 57807.069458 Epsilon 0.0476308440844\n",
      "Epoch  111 loss: 9.57283882052 Reward: 15.0 Total Q: 39826.1791687 Epsilon 0.0476308440844\n",
      "Epoch  112 loss: 11.9644985497 Reward: 38.0 Total Q: 70474.1549683 Epsilon 0.0476308440844\n",
      "Epoch  113 loss: 4.51277195662 Reward: 16.0 Total Q: 37228.9162598 Epsilon 0.0476308440844\n",
      "Epoch  114 loss: 8.22161944956 Reward: 21.0 Total Q: 47783.9544067 Epsilon 0.0476308440844\n",
      "Epoch  115 loss: 9.36400689557 Reward: 17.0 Total Q: 50652.6978378 Epsilon 0.0476308440844\n",
      "Epoch  116 loss: 7.79539721459 Reward: 26.0 Total Q: 55788.9204102 Epsilon 0.0476308440844\n",
      "Epoch  117 loss: 7.12615294009 Reward: 22.0 Total Q: 43458.7344666 Epsilon 0.0476308440844\n",
      "Epoch  118 loss: 4.74807457998 Reward: 13.0 Total Q: 31683.9672546 Epsilon 0.0476308440844\n",
      "Epoch  119 loss: 8.74902672693 Reward: 21.0 Total Q: 34456.4823608 Epsilon 0.0476308440844\n",
      "Epoch  120 loss: 7.21855099499 Reward: 19.0 Total Q: 32571.0712585 Epsilon 0.0476308440844\n",
      "Epoch  121 loss: 14.3624712341 Reward: 18.0 Total Q: 46519.1801453 Epsilon 0.0476308440844\n",
      "Epoch  122 loss: 5.82305171341 Reward: 12.0 Total Q: 32344.7240601 Epsilon 0.0476308440844\n",
      "Epoch  123 loss: 5.11930277199 Reward: 5.0 Total Q: 22942.7621155 Epsilon 0.0476308440844\n",
      "Epoch  124 loss: 21.1410355866 Reward: 25.0 Total Q: 45317.9664917 Epsilon 0.0476308440844\n",
      "Epoch  125 loss: 8.01659834385 Reward: 24.0 Total Q: 55360.0287476 Epsilon 0.0476308440844\n",
      "Epoch  126 loss: 7.77851311117 Reward: 25.0 Total Q: 46510.9485474 Epsilon 0.0476308440844\n",
      "Epoch  127 loss: 10.1020031795 Reward: 11.0 Total Q: 31426.9068604 Epsilon 0.0476308440844\n",
      "Epoch  128 loss: 9.8555034399 Reward: 25.0 Total Q: 60303.3303833 Epsilon 0.0476308440844\n",
      "Epoch  129 loss: 3.42679950595 Reward: 19.0 Total Q: 32314.5404053 Epsilon 0.0476308440844\n",
      "Epoch  130 loss: 8.95239108056 Reward: 37.0 Total Q: 81304.0178833 Epsilon 0.0476308440844\n",
      "Epoch  131 loss: 11.0166847557 Reward: 36.0 Total Q: 71114.4158325 Epsilon 0.0476308440844\n",
      "Epoch  132 loss: 3.55110575631 Reward: 9.0 Total Q: 33820.4275513 Epsilon 0.0476308440844\n",
      "Epoch  133 loss: 9.17481657863 Reward: 30.0 Total Q: 70055.6939087 Epsilon 0.0476308440844\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-8e0047396b07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0;31m# or future discounted q-values, in case episodes are still running.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mrewards\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                     \u001b[0;31m#print t, a, t.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1570\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1571\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1572\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1574\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1200\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1203\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2073\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2075\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2076\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nb_epochs = 1000\n",
    "batch_size = 128\n",
    "epsilon = .8\n",
    "gamma = .8\n",
    "K_frames = 4 #frames to skip each step\n",
    "\n",
    "model  = build_model(STATE_LENGTH = K_frames, FRAME_WIDTH = 84, FRAME_HEIGHT = 84,output_size=env.action_space.n)\n",
    "model.compile(RMSprop(), 'MSE')\n",
    "\n",
    "exp_replay = experience_replay(batch_size)\n",
    "exp_replay.next()  # Start experience-replay coroutine\n",
    "\n",
    "loss = 0\n",
    "rewards = 0\n",
    "q_values = 0\n",
    "\n",
    "for i in xrange(nb_epochs):\n",
    "    \n",
    "    \n",
    "    if(epsilon > 0.05):\n",
    "        epsilon = epsilon*0.95\n",
    "    \n",
    "    #ep = episode()\n",
    "    #S, won = ep.next()  # Start coroutine of single entire episode\n",
    "    action = np.random.randint(0, 6) #first action of epoch is random\n",
    "    S = env.reset()\n",
    "    #print S\n",
    "    \n",
    "    print 'Epoch ', i + 1, 'loss:', loss, \"Reward:\", rewards, \"Total Q:\", q_values, \"Epsilon\", epsilon     \n",
    "    rewards = 0\n",
    "    loss = 0.\n",
    "    q_values = 0\n",
    "    done = 0\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            \n",
    "            ls = list()\n",
    "            ls.append(S)\n",
    "            \n",
    "            action = np.random.randint(0, 6) \n",
    "            if np.random.random() < epsilon:\n",
    "                # Get the index of the maximum q-value of the model.\n",
    "                # Subtract one because actions are either -1, 0, or 1 #DONT DO THAT\n",
    "                \n",
    "                for i in range(K_frames-1):\n",
    "                    s, r, done, info = env.step(action)\n",
    "                    ls.append(s)\n",
    "                    rewards+=r\n",
    "\n",
    "                    if(done):\n",
    "                        done = True\n",
    "                        break\n",
    "                    #print s.shape\n",
    "                S = stackIt(ls)\n",
    "                action = np.argmax(model.predict(S))\n",
    "            else:\n",
    "                \n",
    "                for i in range(K_frames-1):\n",
    "                    s, r, done, info = env.step(action)\n",
    "                    ls.append(s)\n",
    "                    rewards+=r\n",
    "\n",
    "                    if(done):\n",
    "                        done = True\n",
    "                        break\n",
    "                    #print \"Tam of s when not epsilon: \", s.shape\n",
    "                S = stackIt(ls)\n",
    "                \n",
    "            if(done):\n",
    "                done = True\n",
    "                break\n",
    "            ## GETTING NEXT STATE ##\n",
    "            S_prime, r, done, info = env.step(action)\n",
    "            ls = list()\n",
    "            ls.append(S_prime)\n",
    "            \n",
    "            for i in range(K_frames-1):\n",
    "                s, r, done, info = env.step(action)\n",
    "                ls.append(s)\n",
    "                rewards+=r\n",
    "                if(done):\n",
    "                    done = True\n",
    "                    break\n",
    "                #print \"Tam of s when not epsilon: \", s.shape\n",
    "            if(done):\n",
    "                done = True\n",
    "                break\n",
    "            S_prime = stackIt(ls)\n",
    "            \n",
    "            experience = (S, action, r, S_prime)\n",
    "            \n",
    "            S_prime, r, done, info = env.step(action)\n",
    "            S = S_prime\n",
    "            \n",
    "            batch = exp_replay.send(experience)\n",
    "            \n",
    "            if batch:\n",
    "                inputs = []\n",
    "                targets = []\n",
    "                for s, a, r, s_prime in batch:\n",
    "                    # The targets of unchosen actions are the q-values of the model,\n",
    "                    # so that the corresponding errors are 0. The targets of chosen actions\n",
    "                    # are either the rewards, in case a terminal state has been reached, \n",
    "                    # or future discounted q-values, in case episodes are still running.\n",
    "                    rewards +=r\n",
    "                    t = model.predict(s)\n",
    "                    #print t, a, t.shape\n",
    "                    t[0][a] = r\n",
    "                    #print a\n",
    "                    if not r:\n",
    "                        t[0][a] = r + gamma * np.argmax(model.predict(s_prime))\n",
    "                    targets.append(t[0])\n",
    "                    inputs.append(s[0])\n",
    "                q_values += np.sum(targets)\n",
    "                loss += model.train_on_batch(np.array(inputs), np.array(targets))\n",
    "            #print loss\n",
    "    except StopIteration:\n",
    "        pass\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print 'Epoch ', i + 1, 'loss:', loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.convolutional.Conv2D object at 0x7f6b00756c50>\n"
     ]
    }
   ],
   "source": [
    "print model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('breakout.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def save_img():\n",
    "    frame = 0\n",
    "    while True:\n",
    "        screen = (yield)\n",
    "        plt.imshow(screen[0], interpolation='none')\n",
    "        plt.savefig('images/%03i.png' % frame)\n",
    "        frame += 1\n",
    "    \n",
    "img_saver = save_img()\n",
    "img_saver.next()\n",
    "\n",
    "for _ in xrange(10):\n",
    "    g = episode()\n",
    "    S, _ = g.next()\n",
    "    img_saver.send(S)\n",
    "    try:\n",
    "        while True:\n",
    "            act = np.argmax(model.predict(S[np.newaxis]), axis=-1)[0] - 1\n",
    "            S, _ = g.send(act)\n",
    "            img_saver.send(S)\n",
    "\n",
    "    except StopIteration:\n",
    "        g.close()\n",
    "\n",
    "img_saver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
